{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MrH3HBY48Yal"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "      train = True,\n",
        "      download = True,\n",
        "      root = 'data',\n",
        "      transform = ToTensor(),\n",
        "      # target_transform = ToTensor()\n",
        "    )\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "        root = 'data',\n",
        "        download = False,\n",
        "        train = False,\n",
        "        transform = ToTensor(),\n",
        "        #\n",
        "        target_transform = ToTensor()\n",
        "    )"
      ],
      "metadata": {
        "id": "DMbzq1Va8ieB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742c7270-c2f7-44c4-f2d1-e753ab12d7cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15005538.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 271252.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4971482.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4723753.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "          batch_size =  32,\n",
        "          dataset = train_data,\n",
        "          shuffle = True\n",
        "      )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "          dataset = test_data,\n",
        "          batch_size = 32,\n",
        "      )"
      ],
      "metadata": {
        "id": "VSLRvHi89i3i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
        "train_features_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njJXaewx-MuG",
        "outputId": "4ce18050-ce7d-471e-e04a-f4887651d594"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "WHBO6lnW-ZTJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,input_channel, output_features):\n",
        "    super().__init__()\n",
        "    self.kernel_size = (3,3)\n",
        "    self.stride = (2,2)\n",
        "    self.convmodel = torch.nn.Sequential(\n",
        "      torch.nn.Conv2d(in_channels = input_channel, out_channels = 12, kernel_size = self.kernel_size , stride = self.stride),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.Conv2d(in_channels = 12, out_channels=3, kernel_size = self.kernel_size, stride =self.stride),\n",
        "      torch.nn.MaxPool2d(kernel_size = self.kernel_size,stride = self.stride),\n",
        "      torch.nn.Flatten()\n",
        "    )\n",
        "\n",
        "    self.linearmodel = torch.nn.Sequential(\n",
        "        torch.nn.Flatten(start_dim=1,end_dim=-1),\n",
        "        torch.nn.Linear(in_features = 12, out_features = 10),\n",
        "        torch.nn.Softmax(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.convmodel(x)\n",
        "    x = self.linearmodel(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FBMIUzq_-_Pc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 34"
      ],
      "metadata": {
        "id": "HK75q5Py_fXc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(seed)\n",
        "model = ConvolutionalClassifier(input_channel = 1, output_features = 1)"
      ],
      "metadata": {
        "id": "HAlFiw4F_EMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5j4AUB3_GjJ",
        "outputId": "e3eab96e-6450-4010-e2ba-1988664b7b64"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchinfo\n",
        "torchinfo.summary(model,input_size=(1,1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njos9LE0_HLd",
        "outputId": "9ab70db7-194d-4f7c-c1f6-0383c413dbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvolutionalClassifier                  [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 12]                   --\n",
              "│    └─Conv2d: 2-1                       [1, 12, 13, 13]           120\n",
              "│    └─ReLU: 2-2                         [1, 12, 13, 13]           --\n",
              "│    └─Conv2d: 2-3                       [1, 3, 6, 6]              327\n",
              "│    └─MaxPool2d: 2-4                    [1, 3, 2, 2]              --\n",
              "│    └─Flatten: 2-5                      [1, 12]                   --\n",
              "├─Sequential: 1-2                        [1, 10]                   --\n",
              "│    └─Flatten: 2-6                      [1, 12]                   --\n",
              "│    └─Linear: 2-7                       [1, 10]                   130\n",
              "│    └─Softmax: 2-8                      [1, 10]                   --\n",
              "==========================================================================================\n",
              "Total params: 577\n",
              "Trainable params: 577\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.03\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.02\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.02\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(params = model.parameters(),lr = 0.01)"
      ],
      "metadata": {
        "id": "ibP6Tdh4_JRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "torch.manual_seed(seed)\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  train_l = 0\n",
        "  for x,y in train_loader:\n",
        "    train_pred = model(x)\n",
        "    loss = loss_fn(train_pred,y)\n",
        "    train_l += loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if epoch%10==0:\n",
        "    test_l = 0\n",
        "    train_l/= len(train_loader)\n",
        "    for t_x,t_y in test_loader:\n",
        "      test_y = model(t_x)\n",
        "      test_l+= loss_fn(test_y,t_y)\n",
        "    test_l/=len(test_loader)\n",
        "    print(f\"{epoch} \\t train loss : {train_l} \\t test loss : {test_l}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL9_kl3j_MOQ",
        "outputId": "cef82692-c650-49d6-c352-9e1888881b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \t train loss : 2.30222225189209 \t test loss : 2.3015670776367188\n",
            "10 \t train loss : 1.941670298576355 \t test loss : 1.9328166246414185\n",
            "20 \t train loss : 1.839295744895935 \t test loss : 1.8378793001174927\n",
            "30 \t train loss : 1.7987815141677856 \t test loss : 1.8003718852996826\n",
            "40 \t train loss : 1.7784082889556885 \t test loss : 1.7814797163009644\n",
            "50 \t train loss : 1.765880823135376 \t test loss : 1.7701894044876099\n",
            "60 \t train loss : 1.7576712369918823 \t test loss : 1.7631553411483765\n",
            "70 \t train loss : 1.7517908811569214 \t test loss : 1.7578370571136475\n",
            "80 \t train loss : 1.7469817399978638 \t test loss : 1.7531683444976807\n",
            "90 \t train loss : 1.7427291870117188 \t test loss : 1.7489087581634521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_l = 0\n",
        "with torch.inference_mode():\n",
        "  for t_x,t_y in test_loader:\n",
        "    test_y = model(t_x)\n",
        "    test_l+= loss_fn(test_y,t_y)\n",
        "  test_l/=len(test_loader)\n",
        "  print(f\"loss : {test_l}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Rl0RJBIEGS",
        "outputId": "3dd6bbbe-3b83-4016-d0d8-cc3bec21c6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 1.7455533742904663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    It took around 26minutes to  run on cpu"
      ],
      "metadata": {
        "id": "k7hGJd-qHaE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Now change the runtime to GPU***"
      ],
      "metadata": {
        "id": "EyhBJ-H4Ho82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "8Ap7aIOpF8g5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ocM5jcH-Ehb9",
        "outputId": "a17758ed-219b-462a-9239-351393f37ad4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model on GPU\n",
        "torch.manual_seed(seed)\n",
        "gpu_model = ConvolutionalClassifier(input_channel=1, output_features = 1)\n",
        "gpu_model.to(device)"
      ],
      "metadata": {
        "id": "ehep8dMn_z8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfda6ed5-2a35-4d1c-cce7-90d40dffd24f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalClassifier(\n",
              "  (convmodel): Sequential(\n",
              "    (0): Conv2d(1, 12, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(12, 3, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (linearmodel): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=12, out_features=10, bias=True)\n",
              "    (2): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizers are similar\n",
        "gpu_loss_fn = torch.nn.CrossEntropyLoss()\n",
        "gpu_optimizer = torch.optim.Adadelta(params = gpu_model.parameters(),lr = 0.01)"
      ],
      "metadata": {
        "id": "7M-H6ccPGF_4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu model training\n",
        "torch.manual_seed(seed)\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  gpu_model.train()\n",
        "  for x,y in train_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = gpu_model(x)\n",
        "    loss = gpu_loss_fn(y_pred,y)\n",
        "    gpu_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    gpu_optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml96dYULGRVg",
        "outputId": "c414d826-1c6b-4946-8fcc-22d90c9ca967"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gpu_model.state_dict(),'savedmodel.h5')"
      ],
      "metadata": {
        "id": "lRj2HVW-JFRa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = ConvolutionalClassifier(input_channel=1, output_features=1)\n",
        "new_model.load_state_dict(torch.load('savedmodel.h5'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mULUb82JsR4",
        "outputId": "2fdaef42-db40-43d9-a427-d06796efe7ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0SRIVAmKuoI",
        "outputId": "48529a89-c263-417b-bb24-98a4d4efc7f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7a7f76132420>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzHKOq-mMB_r",
        "outputId": "715151e5-9353-40d7-8653-95f9261db4ca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7a7f76133300>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZIX-QkxMFDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}